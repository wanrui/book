# traffic server 超时参数说明
## 1. 相关参数列表
### 1.1 父相关参数
#### 1.1.1 vcache版本
```
##############################
# parent proxy configuration #
##############################
#是否开启父节点
CONFIG proxy.config.http.parent_proxy_routing_enable INT 0
#当父节点不可用时，重试父节点的时间
CONFIG proxy.config.http.parent_proxy.retry_time INT 300
# Parent fail threshold is the number of request that must
# fail within the retry window for the parent to be marked
# down
#父节点不可用的阈值为重试一定次数失败后即标记为失败
#父节点探测次数，失败则任务父节点不可用
CONFIG proxy.config.http.parent_proxy.fail_threshold INT 10
#在跳过父节点缓存或者是回复请求失败之前允许连接尝试的次数（依赖于bypass.config的go_direct选项）
CONFIG proxy.config.http.parent_proxy.total_connect_attempts INT 4
#当有多个父节点时，每个父节点允许的连接数
CONFIG proxy.config.http.parent_proxy.per_parent_connect_attempts INT 2
#父节点缓存的连接超时的超时时间
CONFIG proxy.config.http.parent_proxy.connect_attempts_timeout INT 30
#配置ts发送代理身份验证头信息到父缓存
CONFIG proxy.config.http.forward.proxy_auth_to_parent INT 0
```

#### 1.1.2 traffic server 6.1.1 官方版本
```
##############################################################################
# Parent proxy configuration, in addition to these settings also see parent.config. Docs:
#    https://docs.trafficserver.apache.org/records.config#parent-proxy-configuration
#    https://docs.trafficserver.apache.org/en/latest/reference/configuration/parent.config.en.html
##############################################################################
#是否开启父节点
CONFIG proxy.config.http.parent_proxy_routing_enable INT 0
#当父节点不可用时，重试父节点的时间
CONFIG proxy.config.http.parent_proxy.retry_time INT 300
#父节点缓存的连接超时的超时时间
CONFIG proxy.config.http.parent_proxy.connect_attempts_timeout INT 30
#配置ts发送代理身份验证头信息到父缓存
CONFIG proxy.config.http.forward.proxy_auth_to_parent INT 0
CONFIG proxy.config.http.uncacheable_requests_bypass_parent INT 1
```

## 1.2 连接相关参数
### 1.2.1  vcache版本
```
###################################
# HTTP connection timeouts (secs) #
###################################
# out: proxy -> origin server connection
# in : ua -> proxy connection
#指定事务结束后为保证后续进入请求而继续保持连接的时间
CONFIG proxy.config.http.keep_alive_no_activity_timeout_in INT 115
#指定事务结束后为保证后续出口请求而继续保持连接的时间
CONFIG proxy.config.http.keep_alive_no_activity_timeout_out INT 120
#指定如果发生网络拥塞时（入），ts服务器多长时间与客户端断开连接
CONFIG proxy.config.http.transaction_no_activity_timeout_in INT 30
#知道如果发生网络拥塞时（出），ts服务器多长时间后与客户端断开连接
CONFIG proxy.config.http.transaction_no_activity_timeout_out INT 30
#和客户端保持连接的最长时间（入）
CONFIG proxy.config.http.transaction_active_timeout_in INT 900
#和客户端保持连接的最长时间（出）
CONFIG proxy.config.http.transaction_active_timeout_out INT 0
#关闭没有活动的连接的超时时间
CONFIG proxy.config.http.accept_no_activity_timeout INT 120
#指定预缓存服务器连接多久后断开与源服务器的连接
CONFIG proxy.config.http.background_fill_active_timeout INT 60
#?总文件大小的比例已转移时，客户端中止在该代表继续从原始服务器获取的文件，把它转换成高速缓存
CONFIG proxy.config.http.background_fill_completed_threshold FLOAT 0.5
```

### 1.2.2  traffic server 6.1.1 官方版本
```
##############################################################################
# HTTP connection timeouts (secs). Docs:
#    https://docs.trafficserver.apache.org/records.config#http-connection-timeouts
##############################################################################
CONFIG proxy.config.http.keep_alive_no_activity_timeout_in INT 115
CONFIG proxy.config.http.keep_alive_no_activity_timeout_out INT 120
CONFIG proxy.config.http.transaction_no_activity_timeout_in INT 30
CONFIG proxy.config.http.transaction_no_activity_timeout_out INT 30
CONFIG proxy.config.http.transaction_active_timeout_in INT 900
CONFIG proxy.config.http.transaction_active_timeout_out INT 0
CONFIG proxy.config.http.accept_no_activity_timeout INT 120
CONFIG proxy.config.net.default_inactivity_timeout INT 86400
##############################################################################
```


## 1.3 源站端相关参数
### 1.3.1  vcache版本
```
   ##################################
   # origin server connect attempts #
   ##################################
   
#当源服务器没有响应时，ts最大重试次数
CONFIG proxy.config.http.connect_attempts_max_retries INT 6
#当源服务器不可用时，ts最大重试次数
CONFIG proxy.config.http.connect_attempts_max_retries_dead_server INT 3
#如果该服务器DNS有做轮询，则在轮询条目标记为down之前允许尝试连接失败的最大值
CONFIG proxy.config.http.connect_attempts_rr_retries INT 3
#源服务器连接的超时时间
CONFIG proxy.config.http.connect_attempts_timeout INT 30
#POST/PUT请求时，源服务器的超时值
CONFIG proxy.config.http.post_connect_attempts_timeout INT 1800
#Server记录服务器down的时间，在该段时间内认为服务器down(以秒记)
CONFIG proxy.config.http.down_server.cache_time INT 300
#在一个客户端因为源服务器响应太慢而放弃请求之后到TS标记该服务器不可达之间的秒数
CONFIG proxy.config.http.down_server.abort_threshold INT 10
```

### 1.3.2 traffic server 6.1.1 官方版本
```
##############################################################################
# Origin server connect attempts. Docs:
#    https://docs.trafficserver.apache.org/records.config#origin-server-connect-attempts
##############################################################################
CONFIG proxy.config.http.connect_attempts_max_retries INT 3
CONFIG proxy.config.http.connect_attempts_max_retries_dead_server INT 1
CONFIG proxy.config.http.connect_attempts_rr_retries INT 3
CONFIG proxy.config.http.connect_attempts_timeout INT 30
CONFIG proxy.config.http.post_connect_attempts_timeout INT 1800
CONFIG proxy.config.http.down_server.cache_time INT 60
CONFIG proxy.config.http.down_server.abort_threshold INT 10
```
## 2. 功能说明
1. at most two netvc(connections) on a given transaction(txn)
2. client side conncetion (in);server side conncection(out)
3. separate inactivity,active timers for each netvc at any given state
4. active_timer_bg_fill on a premature client abort(during download)
5. connect_timer runs until the first byte from origin(ts-242)
6. "accpect " indicates successful ssl handshake for  tls connctions

```
inactivity_timer_default-->CONFIG proxy.config.net.default_inactivity_timeout INT 86400（6.1.1 版本才有的配置）
inactivity_timer_accept(in)-->CONFIG proxy.config.http.accept_no_activity_timeout INT 120
inactivity_timer_txn(in)-->CONFIG proxy.config.http.transaction_no_activity_timeout_in INT 30
activity_timer_txn(in)-->CONFIG proxy.config.http.transaction_active_timeout_in INT 900
inactivity_timer_ka(in)--> CONFIG proxy.config.http.keep_alive_no_activity_timeout_in INT 115
connect_timer-->CONFIG proxy.config.http.connect_attempts_timeout INT 30
inactivity_timer_txn(out)-->CONFIG proxy.config.http.transaction_no_activity_timeout_out INT 30
activicty_timer_txn(out)-->CONFIG proxy.config.http.transaction_active_timeout_out INT 0
activity_time_bg_fill(out)-->CONFIG proxy.config.http.background_fill_active_timeout INT 60
inactiviy_timer_ka(out)-->CONFIG proxy.config.http.keep_alive_no_activity_timeout_out INT 120
```



## 3. 功能原理

```
void
HttpSM::attach_server_session(HttpServerSession * s)
{
  hsm_release_assert(server_session == NULL);
  hsm_release_assert(server_entry == NULL);
  hsm_release_assert(s->state == HSS_ACTIVE);
  server_session = s;
  server_session->transact_count++;

  // Set the mutex so that we have soemthing to update
  //   stats with
  server_session->mutex = this->mutex;

  HTTP_INCREMENT_DYN_STAT(http_current_server_transactions_stat);
  ++s->server_trans_stat;

  // Record the VC in our table
  server_entry = vc_table.new_entry();
  server_entry->vc = server_session;
  server_entry->vc_type = HTTP_SERVER_VC;
  server_entry->vc_handler = &HttpSM::state_send_server_request_header;

  // Initate a read on the session so that the SM and not
  //  session manager will get called back if the timeout occurs
  //  or the server closes on us.  The IO Core now requires us to
  //  do the read with a buffer and a size so preallocate the
  //  buffer
  server_buffer_reader = server_session->get_reader();
  server_entry->read_vio = server_session->do_io_read(this, INT64_MAX, server_session->read_buffer);

  // This call cannot be canceled or disabled on Windows at a different
  // time (callstack). After this function, all transactions will send
  // a request to the origin server. It is possible that read events
  // for the response come in before the write events for sending the
  // request itself. In state_send_server_request(), we try to disable
  // reading until writing the request completed. That turned out to be
  // for the second do_io_read(), the way to reenable() reading once
  // disabled, but still the result of this do_io_read came in. For this
  // read holds: server_entry->read_vio == INT64_MAX
  // This block of read events gets undone in setup_server_read_response()

  // Transfer control of the write side as well
  server_session->do_io_write(this, 0, NULL);

  // Setup the timeouts
  // Set the inactivity timeout to the connect timeout so that we
  //   we fail this server if it doesn't start sending the response
  //   header
  MgmtInt connect_timeout;

  if (t_state.method == HTTP_WKSIDX_POST || t_state.method == HTTP_WKSIDX_PUT) {
    connect_timeout = t_state.txn_conf->post_connect_attempts_timeout;
  } else if (t_state.current.server == &t_state.parent_info) {
    connect_timeout = t_state.http_config_param->parent_connect_timeout;
  } else {
    connect_timeout = t_state.txn_conf->connect_attempts_timeout;
  }
  if (t_state.pCongestionEntry != NULL)
    connect_timeout = t_state.pCongestionEntry->connect_timeout();

  if (t_state.api_txn_connect_timeout_value != -1) {
    server_session->get_netvc()->set_inactivity_timeout(HRTIME_MSECONDS(t_state.api_txn_connect_timeout_value));
  } else {
    server_session->get_netvc()->set_inactivity_timeout(HRTIME_SECONDS(connect_timeout));
  }

  if (t_state.api_txn_active_timeout_value != -1) {
    server_session->get_netvc()->set_active_timeout(HRTIME_MSECONDS(t_state.api_txn_active_timeout_value));
  } else {
    server_session->get_netvc()->set_active_timeout(HRTIME_SECONDS(t_state.txn_conf->transaction_active_timeout_out));
  }

  if (plugin_tunnel_type != HTTP_NO_PLUGIN_TUNNEL) {
    server_session->private_session = true;
  }
}
```


```
int
HttpSM::state_raw_http_server_open(int event, void *data)
{
  STATE_ENTER(&HttpSM::state_raw_http_server_open, event);
  ink_assert(server_entry == NULL);
  milestones.server_connect_end = ink_get_hrtime();
  NetVConnection *netvc = NULL;

  pending_action = NULL;
  switch (event) {
  case NET_EVENT_OPEN:

    if (t_state.pCongestionEntry != NULL) {
      t_state.pCongestionEntry->connection_opened();
      t_state.congestion_connection_opened = 1;
    }
    // Record the VC in our table
    server_entry = vc_table.new_entry();
    server_entry->vc = netvc = (NetVConnection *) data;
    server_entry->vc_type = HTTP_RAW_SERVER_VC;
    t_state.current.state = HttpTransact::CONNECTION_ALIVE;

    netvc->set_inactivity_timeout(HRTIME_SECONDS(t_state.txn_conf->transaction_no_activity_timeout_out));
    netvc->set_active_timeout(HRTIME_SECONDS(t_state.txn_conf->transaction_active_timeout_out));
    break;

  case VC_EVENT_ERROR:
  case NET_EVENT_OPEN_FAILED:
    if (t_state.pCongestionEntry != NULL) {
      t_state.current.state = HttpTransact::CONNECTION_ERROR;
      call_transact_and_set_next_state(HttpTransact::HandleResponse);
      return 0;
    } else {
      t_state.current.state = HttpTransact::OPEN_RAW_ERROR;
      // use this value just to get around other values
      t_state.hdr_info.response_error = HttpTransact::STATUS_CODE_SERVER_ERROR;
    }
    break;
  case CONGESTION_EVENT_CONGESTED_ON_F:
    t_state.current.state = HttpTransact::CONGEST_CONTROL_CONGESTED_ON_F;
    break;
  case CONGESTION_EVENT_CONGESTED_ON_M:
    t_state.current.state = HttpTransact::CONGEST_CONTROL_CONGESTED_ON_M;
    break;

  default:
    ink_release_assert(0);
    break;
  }

  call_transact_and_set_next_state(HttpTransact::OriginServerRawOpen);
  return 0;

}
```

## 4. 调整策略
